{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2265ec12-070e-440a-8cd4-2b233b777664",
   "metadata": {},
   "source": [
    "# Transfer Learning and Fine-Tuning with TensorFlow\n",
    "\n",
    "# Step 1: Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07d5e88-e159-499d-915c-f988f2f5c37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995626ae",
   "metadata": {},
   "source": [
    "# Step 2: Download and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f746bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad2c20a",
   "metadata": {},
   "source": [
    "# Check if dataset directory already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3808e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('cats_and_dogs_filtered')\n",
    "if not data_dir.exists():\n",
    "    print(\"Downloading cats and dogs dataset...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81179932",
   "metadata": {},
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e22ddfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35258ba9",
   "metadata": {},
   "source": [
    " # Create the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a1fdd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('cats_and_dogs_filtered', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9577dd1f",
   "metadata": {},
   "source": [
    "# Manually extract the zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8b9f86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting zip file...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extraction complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting zip file...\")\n",
    "with zipfile.ZipFile(path_to_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "    print(\"Dataset extraction complete!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9b811",
   "metadata": {},
   "source": [
    "# Set path to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77d9bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'cats_and_dogs_filtered'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2949f5a",
   "metadata": {},
   "source": [
    "# Verify directories exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "348ff4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b85e7e0",
   "metadata": {},
   "source": [
    "# Print directory information to help debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0331a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train directory: cats_and_dogs_filtered\\train\n",
      "Train directory exists: True\n",
      "Validation directory: cats_and_dogs_filtered\\validation\n",
      "Validation directory exists: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train directory: {train_dir}\")\n",
    "print(f\"Train directory exists: {os.path.exists(train_dir)}\")\n",
    "print(f\"Validation directory: {validation_dir}\")\n",
    "print(f\"Validation directory exists: {os.path.exists(validation_dir)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d951fb81",
   "metadata": {},
   "source": [
    "# List subdirectories to confirm dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17a53402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subdirectories: ['cats', 'dogs']\n",
      "Validation subdirectories: ['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(train_dir):\n",
    "    print(\"Train subdirectories:\", os.listdir(train_dir))\n",
    "if os.path.exists(validation_dir):\n",
    "    print(\"Validation subdirectories:\", os.listdir(validation_dir))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8c557f",
   "metadata": {},
   "source": [
    "# Create train and validation datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad4aef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE)\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE)\n",
    "\n",
    "\n",
    "# TensorBoard setup for visualization\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, \n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "initial_epochs = 10\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=initial_epochs,\n",
    "    callbacks=[cp_callback, tensorboard_callback]\n",
    ")\n",
    "\n",
    "# Step 10: Learning curves\n",
    "# ----------------------\n",
    "# Plot the training and validation accuracy/loss\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "# Step 11: Fine tuning\n",
    "# ------------------\n",
    "# Un-freeze the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "fine_tune_at = 100  # Choose a layer from which to fine-tune\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # Much lower learning rate\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# View the trainable status of each layer\n",
    "print(\"Number of layers in the base model:\", len(base_model.layers))\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "\n",
    "# Step 12: Continue training with fine-tuning\n",
    "# ----------------------------------------\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "# Start from the epoch we left off\n",
    "history_fine = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    callbacks=[cp_callback, tensorboard_callback]\n",
    ")\n",
    "\n",
    "# Step 13: Learning curves with fine-tuning\n",
    "# --------------------------------------\n",
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.axvline(x=initial_epochs-1, color='r', linestyle='--')\n",
    "plt.annotate('Start Fine Tuning', xy=(initial_epochs, 0.8), xytext=(initial_epochs, 0.65),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.axvline(x=initial_epochs-1, color='r', linestyle='--')\n",
    "plt.annotate('Start Fine Tuning', xy=(initial_epochs, 0.8), xytext=(initial_epochs, 0.25),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "# Step 14: Evaluation and prediction\n",
    "# -------------------------------\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_dataset)\n",
    "print('Test accuracy :', accuracy)\n",
    "\n",
    "# Make predictions\n",
    "for image_batch, labels_batch in validation_dataset.take(1):\n",
    "    images = image_batch.numpy()\n",
    "    labels = labels_batch.numpy()\n",
    "    predictions = model.predict(image_batch)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].astype('uint8'))\n",
    "        \n",
    "        prediction = np.argmax(predictions[i])\n",
    "        if prediction == labels[i]:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        \n",
    "        plt.title(f\"Actual: {class_names[labels[i]]}\\nPredicted: {class_names[prediction]}\", color=color)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Step 15: Save the model\n",
    "# ---------------------\n",
    "model.save('cats_dogs_transfer_learning_model')\n",
    "print(\"Model saved successfully\")\n",
    "\n",
    "# Step 16: Function to predict new images\n",
    "# ------------------------------------\n",
    "def predict_image(image_path):\n",
    "    \"\"\"\n",
    "    Make a prediction on a single image\n",
    "    \"\"\"\n",
    "    img = tf.keras.utils.load_img(\n",
    "        image_path, \n",
    "        target_size=IMG_SIZE\n",
    "    )\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch dimension\n",
    "    \n",
    "    # Preprocess the image similarly to the training data\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0])\n",
    "    \n",
    "    # Display the image and prediction\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {class_names[predicted_class]}\\nConfidence: {confidence:.2f}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return class_names[predicted_class], confidence\n",
    "\n",
    "# Example usage\n",
    "# predict_image('path_to_your_image.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d693d9",
   "metadata": {},
   "source": [
    "# Class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e58d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854f3ecf",
   "metadata": {},
   "source": [
    "# Step 3: Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54c2f6",
   "metadata": {},
   "source": [
    "# Step 4: Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d2fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  tf.keras.layers.RandomZoom(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b04927",
   "metadata": {},
   "source": [
    "# Visualize a few augmented examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[0]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4d006",
   "metadata": {},
   "source": [
    "# Step 5: Rescale pixel values\n",
    "# --------------------------\n",
    "# Create a rescale layer for pixel normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01238976",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3bdaf0",
   "metadata": {},
   "source": [
    "# Step 6: Load pre-trained model\n",
    "# ----------------------------\n",
    "# Load MobileNetV2 without the classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=IMG_SIZE + (3,),  # Input shape should include color channels\n",
    "    include_top=False,  # Exclude the classification head\n",
    "    weights='imagenet'  # Use pre-trained weights from ImageNet\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec74e9b",
   "metadata": {},
   "source": [
    "# Freeze the base model to prevent its weights from being updated during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2832246",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c4426",
   "metadata": {},
   "source": [
    "# Let's look at the base model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b452532",
   "metadata": {},
   "source": [
    "# Step 7: Create the feature extractor\n",
    "# ---------------------------------\n",
    "# Add a global average pooling layer and a dense output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5805bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(len(class_names), activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233384e",
   "metadata": {},
   "source": [
    "# Combine all the layers into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
    "x = data_augmentation(inputs)  # Apply data augmentation\n",
    "x = rescale(x)  # Rescale pixel values\n",
    "x = base_model(x, training=False)  # Pass the image through the base model\n",
    "x = global_average_layer(x)  # Apply global average pooling\n",
    "x = tf.keras.layers.Dropout(0.2)(x)  # Add dropout to prevent overfitting\n",
    "outputs = prediction_layer(x)  # Add the dense output layer\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c963847",
   "metadata": {},
   "source": [
    "# Step 8: Compile the model\n",
    "# -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48923f",
   "metadata": {},
   "source": [
    "# Display the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce4679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc642b4",
   "metadata": {},
   "source": [
    "# Step 9: Train the model\n",
    "# ---------------------\n",
    "# Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa21ac",
   "metadata": {},
   "source": [
    "# Create checkpoint callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c100d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f8d14",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d163c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd6e166",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49912ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df64fcf8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b0379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5ab55af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d47164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76009471",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89834505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa5ec301",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
